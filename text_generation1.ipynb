{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "text_generation1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovpZyIhNIgoq"
      },
      "source": [
        "# Text generation with an RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGyKZj3bzf9p"
      },
      "source": [
        "### Import TensorFlow and other libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yG_n40gFzf9s"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHDoRoc5PKWz"
      },
      "source": [
        "### Download the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RBmeBsFLP4t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7153127-87f6-40d3-d06f-26d15d245d2b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAt0t-9ULhCU"
      },
      "source": [
        "path_to_file = '/content/drive/MyDrive/Colab Notebooks/KindlePreprocessed.txt'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHjdCjDuSvX_"
      },
      "source": [
        "### Read the data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aavnuByVymwK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "072d9766-a659-495f-92b2-472677c26c3f"
      },
      "source": [
        "# read and decode for py2 compat.\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "text = text.replace('\\n', ' ')\n",
        "print(f'Length of text: {len(text)} characters')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 10172244 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Duhg9NrUymwO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9277c617-f2ac-47e9-80ee-c44043bfd242"
      },
      "source": [
        "# Take a look at the first 250 characters in text\n",
        "print(text[:250])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "silly predictable romance, read it in an afternoon with a hangover, that's all I'd recommend this author for. Fortunately it was free and I test drove my new Kindle. This is not a hockey romance! It is Completely misleading and not a great story. I a\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlCgQBRVymwR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "192ecec3-b806-41de-8c58-22a42f8c3346"
      },
      "source": [
        "# unique characters \n",
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "96 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNnrKn_lL-IJ"
      },
      "source": [
        "## Process the text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GMlCe3qzaL9"
      },
      "source": [
        "# convert strings to numerical representation \n",
        "ids_from_chars = preprocessing.StringLookup(\n",
        "    vocabulary=list(vocab), mask_token=None)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd2m3mqkDjRj"
      },
      "source": [
        "# invert representation to recover readable strings\n",
        "chars_from_ids = tf.keras.layers.experimental.preprocessing.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5apvBDn9Ind"
      },
      "source": [
        "# join chars into strings\n",
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NGu-FkO_kYU"
      },
      "source": [
        "# function that takes a sequence, duplicates and shifts it to align the input and label\n",
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxbDTJTw5u_P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9028711-c210-41d5-89a0-f7d8f609ae6f"
      },
      "source": [
        "split_input_target(list(\"Tensorflow\"))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VT_NXga6V8DH"
      },
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n",
        "seq_length = 100\n",
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2pGotuNzf-S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "820245a0-b729-43cd-eae5-c4c49fd7c897"
      },
      "source": [
        "# create training batches w shuffled data to. feed into model\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# buffer size to shuffle the dataset\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6oUuElIMgVx"
      },
      "source": [
        "## Build The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHT8cLh7EAsg"
      },
      "source": [
        "# length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "# embedding dimension\n",
        "embedding_dim = 256\n",
        "# number of RNN units\n",
        "rnn_units = 1024"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wj8HQ2w8z4iO"
      },
      "source": [
        "# build the model (keras.Model subclass)\n",
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IX58Xj9z47Aw"
      },
      "source": [
        "model = MyModel(\n",
        "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxpPGcemWxJD",
        "outputId": "e4fd96d5-a4f6-4049-f2d2-db82a868d1f0"
      },
      "source": [
        "# try model\n",
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 100, 97) # (batch_size, sequence_length, vocab_size)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPGmAAXmVLGC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "763a1c95-8ff9-4b94-c81e-b2fbdec59d90"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        multiple                  24832     \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    multiple                  3938304   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  99425     \n",
            "=================================================================\n",
            "Total params: 4,062,561\n",
            "Trainable params: 4,062,561\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJL0Q0YPY6Ee"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOeWdgxNFDXq"
      },
      "source": [
        "# attach an optimizer and loss function\n",
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HrXTACTdzY-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "741ddeac-06d2-476d-a889-789b9c26d025"
      },
      "source": [
        "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
        "mean_loss = example_batch_loss.numpy().mean()\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", mean_loss)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction shape:  (64, 100, 97)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         4.5744677\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAJfS5YoFiHf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06e817b1-3bbf-4e4a-a874-feb3207dec45"
      },
      "source": [
        "# newly initialized model should have an exponential mean loss approx equal to vocab size\n",
        "tf.exp(mean_loss).numpy()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "96.976395"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDl1_Een6rL0"
      },
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6fWTriUZP-n"
      },
      "source": [
        "# configure checkpoints\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yGBE2zxMMHs"
      },
      "source": [
        "# train the model\n",
        "EPOCHS = 10"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UK-hmKjYVoll",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdc2870f-fe08-4bc9-879b-e138717acebe"
      },
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1573/1573 [==============================] - 84s 52ms/step - loss: 1.6050\n",
            "Epoch 2/10\n",
            "1573/1573 [==============================] - 91s 57ms/step - loss: 1.2188\n",
            "Epoch 3/10\n",
            "1573/1573 [==============================] - 90s 57ms/step - loss: 1.1578\n",
            "Epoch 4/10\n",
            "1573/1573 [==============================] - 91s 57ms/step - loss: 1.1241\n",
            "Epoch 5/10\n",
            "1573/1573 [==============================] - 91s 57ms/step - loss: 1.1016\n",
            "Epoch 6/10\n",
            "1573/1573 [==============================] - 90s 57ms/step - loss: 1.0851\n",
            "Epoch 7/10\n",
            "1573/1573 [==============================] - 91s 57ms/step - loss: 1.0731\n",
            "Epoch 8/10\n",
            "1573/1573 [==============================] - 91s 57ms/step - loss: 1.0647\n",
            "Epoch 9/10\n",
            "1573/1573 [==============================] - 91s 57ms/step - loss: 1.0589\n",
            "Epoch 10/10\n",
            "1573/1573 [==============================] - 91s 57ms/step - loss: 1.0557\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKkD5M6eoSiN"
      },
      "source": [
        "## Generate text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSBU1tHmlUSs"
      },
      "source": [
        "# single step prediction\n",
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # return the characters and model state.\n",
        "    return predicted_chars, states"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqMOuDutnOxK"
      },
      "source": [
        "# initialize model\n",
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkLu7Y8UCMT7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "631839e5-a903-4d9c-98c3-e11c216d3c64"
      },
      "source": [
        "# generate 10 product reviews using the trained model\n",
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['The book', 'The book', 'The book', 'The book', 'The book', 'The book', 'The book', 'The book', 'The book', 'The book'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "words = tf.strings.join(result).numpy().decode(\"utf-8\")\n",
        "print(result, ' ' + '_'*80)\n",
        "print('\\nRun time:', end - start)\n",
        "text_file = open(\"/content/drive/MyDrive/Colab Notebooks/results.txt\", \"w\")\n",
        "n = text_file.write(words)\n",
        "text_file.close()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[b\"The book is right with them like it could be fitting a family situation where you found domesting. But they stuff with a few days saft young by the eye of the Clay's stories is so much you get to it on the window.  Will the beat it was elementary on character everyone looks somewhat too little. Humorously well written, not something building a good book exact pot.  George you! THE MCS: right before they were referenceful. finished the story and different turns in this story. One of the best! Im goinged to read. This is my favorite booklifter when they were spidentalsic and some are generally worth the wait for the next book! Will rately a good say Zena for some reason, resource to refurn to courage on a story of her math, cheating where she is not the heart that astracites the inegirel and love. Trip's playboyandracening too longing to trust him to become older mom bends on life, and doesn't leave you. This book is that. actually didn't disappoint! I have to admit it to you better developed in\"\n",
            " b\"The books spend an involvement with the earlier books in one sitting. Quick read. This was a completely delicious mature.  Del is on part 2 invales mate, incredibly that going through some Santato adventure, and it is off the charts worth of sleep. Bryn is pregnant with a salent but who she didn't want to have a huge skilling way to life, and even her fights her and gots to bring out her life together then moves themselves highly lerry to meet, he bakes it a the house.  And doesn't like humor far, and then went I was caring in the day. Under sons of revealing of the other paranormal darker journey into the activity control rather some defeating her cottakily shown, the rainbows and forgettations involved Ginny Grace......  Knowing to love the other parallel once it was one of those spocker delightfully funny books that am excited and second page. We saspedizately came across this and a coop. I couldn't put it did a fan, and I really like the main characters. Ive done this, but had to impress h\"\n",
            " b\"The books like their first kind of review, by facts I'd read them all of both the wedding.  Quick & sexy chemistry and the book is very founding. But at the same things could really get the foresea. The fact that the 2 dimensions was unheroine, when in mamily, I probably would like this author and have read boff 12.  You have Ann! It is amazing, and I anticipation it was funny and she can't wait to read the book it and it's a spoiler and I was excited to read the others in this series. I think that author irritates two weeks of a pendul/story..........m They were clear, I truly enjoyed this read. I will just wait until he sees the cost while reading that is what I'm getting the see out with them. I wish it would be a bit mouth out. Good story and subject matters...lotharinol smiles.  It discovers with demands of these characters and in this world that I had to wait for the next how I read book 4 in the beginning of the tangente series. This twin mas precise during The Hero Francen comes Risto \"\n",
            " b'The book was well worth the read. Reading this book, Great story line but with sudden internate reactions with intelligences requestion and a 465 because of her powerp version. **Received stick** love is a reply of sign and even more. The personalities shifters like him from his job. She has been investigating love on what Zane contain love on the specacrot catch Auden (love) also others. This story was a dread of medical tension: pilot of heartbreak.   The sexual tension is fine, each know of all the designs of techniquest and true stories you can\\'t know. What can I say?\" Pipe and Marieus Deliantical book to author if I\\'d probably go this mounitatilivily below without the next first one............... by a honest review. AJasumud 5 Your Books out three deadly but this little slower is good. I did not know what the chemistry was way wonderful rowly.  A Shifter book with casta, waiting for the sup to surrounding his career famadas, training of Liletty excitement and she has just surprised me be'\n",
            " b\"The book itself were good, very often part of the story. Thanks I'm glad I read another old Mandille and that webera has always been suffering.  This is a piscely information which is totally awarded in the seriesnto form.....  My Dow servant me, after she is defentited and Liam set out leaping in her in her dipse agen.............. Man/Watido ** 5 is the slight but I would hisked behavior what was histy is too unexpected. Casey, ded some hard writing, & indiscravel without sugh for eagher to change their masters in it.  Thanks because you need to know an attempted hurract then after she is on and buking him feals a way to show that louse in an expire tastest party at the end of her own second trilogy.  4aristic words and amazingly different. These are just useful pleasants, and the author has big layers, a high conclub and jumping under everyone as H is a stand alone with them undeveloped and I think maybe I have to admit, I couldn't put them down. The sweet good thing is can bring the world \"\n",
            " b\"The book delivers but it was easy read,it seems quite clear characters, and I finished her books but grettly in that of me. This was the second book in one or Two whine, but in this genre.  Yechuble!  As ILD feel it felt like you can get myself with the funny books I've read in mu heart. Its a great short story but there is no better. This book was an excellent superfran til through her house, are nearly stumbed and as a whole life, a poorly consten herbele in the species?  Ann, every emotional initiation in this book lacks the other Daniel Formaybally works caught out for motiog, not so much.  Ms. King doesn't defeat them except them with Dr. Lela and Andrea. .  I received a free copy in exchange for an honest review. This story was very believable romance gets gardgring & warmth, but I am so glad I read them all in one book view.  Great story. I read this for a very honor from the amount, love story. It've Fox books the delicious and crime-trighting hero in her, who took five years ago. I wa\"\n",
            " b\"The book started as a stand alone book here this one was really pulled up to form a bit to 30-romance by Connectiming in my contradictions.  This is a fast read, ordinary woman that has a harf-link-waiting fast-paced  soldier. And now she's going to learn about life, the best is that you see that says out she has real jussical experiences around them. Great sex. I read that in one sitting. This was a goof and bonding. I wouldn't care for the next book.  When I pick the Outsful Heart should have been said.... I just love it on immended surprise. His father gets back to because it was unlike, but there is much abrust. Smell will loard on her test in her fears...but the hero actions with just will helps him get the women when it is with inarquest that kept pictured in Sharling's book in a set of emotions that she had more uncomfortable in jail...i  just read more future lords needed to make you feel like being just a bad guy and people who want to learn he has outdone herself from an Alex.  Julie\"\n",
            " b\"The books still prepare for majurting research. I think it was very realist I could give this author at 3.55! 6.5 stars You Beg Melins book, plus, champious read. Very well-written, think that the Leyond Lifes level twenty years caught my emotions out of the world was a professor and with one bit over the edge and they get for them together in a tipe of what we have for Jayce and Thomas was the personality is character but she holds a girlfriend Christmas together.  There were an etchange for musculas in a paranormal series, didnt snow in between, murder and a difficult. Jax was a suckerstalking about it if a heroian, Ms Humborsee in Hased build is trying to find the reality he is somewhat deeper her awesome writing.  After finding our heroine, and the perfect  making the true fantasy realize in this story.  Jenny must alpha mytems. Like they didn't have to be taken from Jack Owen. She blossoms any woman if he decides to look 3 walking out of battle startling, and got sleeping him like I was s\"\n",
            " b\"The books make you want to get the wrapped in or else he had a problem with him but we get to know each other amazing thinkits. It was a quickest read but it was easy to follow.  The outcome, Elizabeth remains Publishing are I think, that's why it's just what many different bear. And the erotic eddille is clean!  That's what order you in the car; or even with some kind of health romance  punch they're face the trials and I felt kill it on earth. There are some sleeping and demons explanation she has deep-goal is great but totals a big support he loved on the past and the Anthologies of Doms was sometimes I just wish it had me hooked!!!! I read most of her books  I've read by this author thanks  o-this book! It has to amazing that I believed. The plot is about their connections to some theme in my life! Didny speed characters I rarely deal with this one.  This book was fun to read while the One tope 5 in Eve need to be lived to the act of love) so that I surr and this was an Hallowey outcast.  \"\n",
            " b\"The book would must not forgive between DaRhiknight but stay fully forces are crying partials. Each kid well and forth the romance. Now he as Isabiliating a town, and the heart of the thought-I'm forced to go them in nowhere, but she doesnt know it was genuine.  It really is still, evens too, as the story is going fasting the plot what he was described due to her and Matthew.  The story was good so far. This book, can she know her nexes to her books voluntarisms with suspense and eyes sometimes, you are living with them eccentricily besides and cocturing moments in the background forms of their own.}. Ws Distand for the vampire Eddies but it ended ut that, one where it was wonderful and too enjoying the main story of 3 days or trent depiction of his future caught by making someone (picking up on the routinest level as it!) the amount of some of the romance of the books, you need to. I'm a chicken I pre-off. I can't wait until the next books!! The dialogue was dramatic, and the secondary charac\"], shape=(10,), dtype=string)  ________________________________________________________________________________\n",
            "\n",
            "Run time: 2.217965841293335\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uKQ8AIHLi9x",
        "outputId": "2b71d5ef-4c19-423e-d262-1533923aaca7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# save model\n",
        "tf.saved_model.save(one_step_model, '/content/drive/MyDrive/Colab Notebooks/one_step')\n",
        "one_step_reloaded = tf.saved_model.load('/content/drive/MyDrive/Colab Notebooks/one_step')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x7fd6500eea90>, because it is not built.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_fn, gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/one_step/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/one_step/assets\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}