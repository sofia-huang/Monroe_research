# Results

To reiterate the objectives for this project, my goal was to generate fake reviews based on Amazon product review data, classify them as either positive or negative and assign an overall rating, then predict whether or not the generated reviews would be considered "helpful". I produced 10 reviews using the GRU Keras model which I trained on the "Kindle Store" subset of the Amazon data [] with 10 epochs. Below is one of the reviews generated. 

*"The books were going to caught up it with a strong holiday wester series. There are some grammar and twists. I loved this book, but it had moments of bad dialogue. It was miss the story that leaves you hanging right into the story as I started reading the book in the series. I was hooked from judgeous woman of angst and ways outside of that. Which I endone who play!! loved every world they keep getting better. The author made the short story to buy a novella that says it and end, but that's of preparing to come. I don't know if it, I'm looking forward to more of her two paranormal errors, and be read. Oh my god.  Linded hard no matter what to do so. The Saga is a pretty good guy and 4 to help pull other if she wants... the reader safe the sense of being sweet, and she is starting to reach them everything. While it was still going against meetamining onlones and act-as she story putting them out of cohe into a first practical ending. Surpers camp to the couple that, turns, and stay kidnapped an"

As you can see, the reviews had a few spelling mistakes and although the words were english, the sentences did not make much sense. I believe that if trained on more epochs or a larger dataset, the results would be significantly better. A graph showing the training loss is shown below. Evaluating a text generation model is tricky and the easiest way is by human judgement. 

### [Back to Main Page](index.md)
